{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# M115 - Image Analysis and Processing, Assignment 2 (Notebook 2)\n\nThis is the second part of Assignment 2 concerning the creation of an intelligent system to detect pneumonia in chest X-ray images, utilising a dataset available at [Kaggle Chest X-Ray Images (Pneumonia) dataset](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia).\n\nHere, a Convolutional Neural Netwrok is developed for that purpose. For the classical ML approach, please refer to [Notebook 1](https://github.com/mdarm/Pneumonia-X-Ray-Detection/blob/main/src/classical-ml.ipynb).","metadata":{}},{"cell_type":"markdown","source":"---\n\nPlease note that this notebook was executed on a Kaggle machine equipped with 16GB of RAM, 2 CPUs and a Tesla P100-PCIE-16GB GPU. If you are rerunning this notebook locally or on a different platform such as Google Colab, you may encounter issues due to differences in the computing environment.\n\nBefore running any other code, it is crucial to execute the first four code cells to import all necessary libraries. Failing to do so may result in matplotlib not functioning correctly.\n\nLastly, run all cells in the order they appear. Many parts of the analysis depend on results or instances created in previous cells.\n\n---","metadata":{}},{"cell_type":"markdown","source":"# Table of Contents\n* [Utilise Available Resources](#scrollTo=resources)\n* [Balance Dataset](#scrollTo=balance)\n* [Data Pre-processing & Augmentation](#scrollTo=augmentation)\n* [CNN Architecture](#scrollTo=cnn)\n  1. [Model fitting](#scrollTo=fit)\n  2. [Model evaluation](#scrollTo=evaluate)\n  3. [Running the model and statistical significance](#scrollTo=ss)\n* [Results and Comparison with Classical ML](#scrollTo=results)\n  1. [Deep learning potential improvements](#scrollTo=improve)","metadata":{}},{"cell_type":"code","source":"# Dependencies for rendering text of matplotlib in LaTeX\n!sudo apt update -y\n!sudo apt install -y cm-super dvipng texlive-latex-extra texlive-latex-recommended","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import random_split\nfrom torch.utils.data import WeightedRandomSampler\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom tqdm import tqdm\nimport time\nimport random\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport pprint\n\n# Consider aesthetics and consistency\nplt.rcParams.update({\n        \"text.usetex\": True,\n        \"font.size\": 15,\n        'mathtext.default': 'regular',\n        'axes.titlesize': 16,\n        \"axes.labelsize\": 16,\n        \"legend.fontsize\": 15,\n        \"xtick.labelsize\": 15,\n        \"ytick.labelsize\": 15,\n        'figure.titlesize': 16,\n        'figure.figsize': (12, 7),\n        'text.latex.preamble': r'\\usepackage{amsmath,amssymb}',\n        \"font.family\": \"serif\",\n        \"font.serif\": \"computer modern roman\",\n        })","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"scrollTo=resources\"></a>\n## Utilise available resources\n\nStarting off, check the available resources.","metadata":{}},{"cell_type":"code","source":"# Check if GPU is available and set the device accordingly\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Device: {device}\")\n\n# Get number of CPU cores\nnum_cpu_cores = os.cpu_count()\nprint(f\"Number of CPU cores: {num_cpu_cores}\")\n\n# Get GPU name\nif torch.cuda.is_available():\n    gpu_name = torch.cuda.get_device_name(0)\n    print(f\"GPU name: {gpu_name}\")\nelse:\n    print(\"No GPU available\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Kaggle's Tesla P100 will be used for training and evaluating the neural model. Also 2 workers (2 CPUs) will be employed for the loading and batching of the data.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"scrollTo=balance\"></a>\n## Balance Dataset","metadata":{}},{"cell_type":"markdown","source":"As was observed in [Notebook 1](https://github.com/mdarm/Pneumonia-X-Ray-Detection/blob/main/src/classical-ml.ipynb), there is a class imbalance, with more pneumonia images than normal images. This can lead to a biased model that may not perform well on the under-represented class. To address this issue, the dataset will be balanced by applying oversampling, undersampling, or a combination of both to make the number of samples in each class equal. This can potentially help the CNN's performance on the under-represented class.","metadata":{}},{"cell_type":"code","source":"def create_weighted_sampler(h, dataset):\n    targets = [label for _, label in dataset]\n    class_counts = np.bincount(targets)\n    class_weights = 1.0 / class_counts\n    weights = [class_weights[label] for label in targets]\n    sampler = WeightedRandomSampler(weights, len(weights))\n    return sampler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"scrollTo=augmentation\"></a>\n## Data Pre-processing & Augmentation","metadata":{}},{"cell_type":"markdown","source":"As opposed to Notebook 1, the preprocessing here will be significantly different given than a CNN will be used.\n\nThe images' center will now be cropped, as opposed to resizing them, which could potentially distort their aspect ratio. The original proportions of the image are preserved by this alteration, aiding the CNN in better learning from the dataset and comprehending the inherent characteristics of the images.\n\nData augmentation techniques will also be leveraged to enhance the diversity of the training dataset. New training examples are generated through subtle alterations to the original images, such as rotation, flipping, and translation. Overfitting is effectively prevented by this strategy, enabling the CNN to become more resilient and proficient in generalising unseen data.\n\nTo correctly implement these techniques, a separate transformation for the training data has been designed, ensuring the test set remains unaffected by these augmentations. The same cautious approach is taken with the validation set, maintaining its authenticity by ensuring it does not undergo any data augmentation.\n\nNormalisation will still be performed on the whole dataset of course.\n\nHere's a brief overview of the aforementioned pipeline:\n\n<div style=\"text-align:center\">\n<img src=\"https://i.imgur.com/aTDU4Vt.png\" alt=\"workflow3\" width=\"500\" height=\"600\"/>\n</div>\n\nWith the augmented volume of data, the CNN can be trained in more epochs without the risk of overfitting. This presents an opportunity to further refine the CNN's learning through additional training iterations, which should result in more accurate predictions.\n\nWith these enhancements and considerations in place, and enhanced ability of the CNN to perform better on unseen data while maintaining robustness against overfitting can reasonably be expected.","metadata":{}},{"cell_type":"code","source":"def prepare_data(h):\n    data_transforms = transforms.Compose([\n        transforms.Resize(size=(h[\"image_size\"], h[\"image_size\"])),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                            std=[0.229, 0.224, 0.225])\n    ])\n\n    data_transforms_train = transforms.Compose([\n        transforms.RandomRotation(20),                                               # Randomly rotate image\n        transforms.RandomHorizontalFlip(p=0.5),                                      # Randomly flip image\n        transforms.ColorJitter(brightness=0.1, contrast=0.1,\n                               saturation=0.1, hue=0.1),                             # Randomly change the b/c/h\n        transforms.RandomApply([transforms.RandomAffine(0, \n                               translate=(0.1, 0.1))], p=0.5),                       # Randomly apply affine transformations with translation\n        transforms.RandomApply([transforms.RandomPerspective(distortion_scale=0.2)],\n                               p=0.5),                                               # Randomly apply perspective transformations\n        transforms.Resize(size=(h[\"image_size\"], h[\"image_size\"])),                  # Resize data\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],                             # Normalise data\n                            std=[0.229, 0.224, 0.225])\n    ])\n\n\n    # Define the validation split percentage\n    val_split = 0.2\n\n    # Load the datasets\n    train_dataset = datasets.ImageFolder(\"/kaggle/input/chest-xray-pneumonia/chest_xray/train/\",\n                                         transform=data_transforms_train)\n    val_dataset = datasets.ImageFolder(\"/kaggle/input/chest-xray-pneumonia/chest_xray/train/\",\n                                       transform=data_transforms)    \n    test_dataset = datasets.ImageFolder(\"/kaggle/input/chest-xray-pneumonia/chest_xray/test/\",\n                                        transform=data_transforms)\n\n    # Create the data loaders for train, validation, and test sets\n    if (h[\"balance\"]):\n        sampler = create_weighted_sampler(h, train_dataset)\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=h[\"batch_size\"],\n                                                   sampler=sampler, num_workers=2)    \n    else:\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=h[\"batch_size\"],\n                                                   shuffle=True, num_workers=2)    \n    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=h[\"batch_size\"],\n                                             shuffle=True, num_workers=2)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=h[\"batch_size\"],\n                                              shuffle=True, num_workers=2)\n\n    return train_loader, val_loader, test_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"scrollTo=cnn\"></a>\n## CNN Architecture","metadata":{}},{"cell_type":"markdown","source":"As mentioned before, the model of choice will be a Convolutional Neural Network. CNNs are designed to work with image data and can capture local patterns more efficiently than fully connected layers. They can also handle larger input images, which can lead to better performance.\n\nThe custom CNN architecture will consist of multiple convolutional layers, followed by max-pooling layers, and finally a fully connected layer for classification. The image size will be set to 256x256, as CNNs can handle larger images better.\n\nHere's a brief overview of the CNN's architecture:\n\n<div style=\"text-align:center\">\n<img src=\"https://i.imgur.com/TcvLftf.png\" alt=\"cnn\" width=\"500\" height=\"600\"/>\n</div>","metadata":{}},{"cell_type":"code","source":"def create_model(h, device):\n    if (h[\"model\"]==\"cnn\"):\n        model = nn.Sequential(\n            nn.Conv2d(3, 16, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(16, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Flatten(),\n            nn.Dropout(0.25),\n            nn.Linear(64 * (h[\"image_size\"] // 8) * (h[\"image_size\"] // 8), 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 2)\n        )\n        model = model.to(device)\n        return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"scrollTo=fit\"></a>\n### Model fitting","metadata":{}},{"cell_type":"markdown","source":"Provided the augmentation of the dataset, the model will be trained for 10 epochs, using a 0.001 learning rate.","metadata":{}},{"cell_type":"code","source":"h = {\n    \"balance\": True,\n    \"num_epochs\": 10,\n    \"batch_size\": 256,\n    \"image_size\": 256,\n    \"lr\": 0.001,\n    \"model\": \"cnn\"\n}\n\n\ndef train_model(h, model, train_loader, val_loader, optimizer, criterion, device):\n    train_loss_history = []\n    val_loss_history = []\n\n    start_time = time.time()\n    num_epochs = h[\"num_epochs\"]\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n\n        progress_bar = tqdm(train_loader, desc=f\"Training epoch {epoch + 1}/{num_epochs}\", leave=False, unit=\"mini-batch\")\n        for inputs, labels in progress_bar:\n            inputs, labels = inputs.to(device), labels.to(device)      \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            progress_bar.set_postfix(loss=loss.item())\n\n\n        val_loss, _, _, _ = evaluate_model(h, model, val_loader, criterion, device)\n        \n        # Store the loss history\n        train_loss = running_loss / len(train_loader)\n        train_loss_history.append(train_loss)\n        val_loss_history.append(val_loss)\n\n        # Calculate elapsed time and remaining time\n        elapsed_time = time.time() - start_time\n        avg_time_per_epoch = elapsed_time / (epoch + 1)\n        remaining_epochs = num_epochs - (epoch + 1)\n        remaining_time = avg_time_per_epoch * remaining_epochs\n\n        # Convert remaining time to minutes and seconds\n        remaining_time_min, remaining_time_sec = divmod(remaining_time, 60)\n\n        print(f\"Epoch [{epoch + 1}/{num_epochs}]: Train Loss: {running_loss / len(train_loader):.4f}, Val Loss: {val_loss:.4f}, Remaining Time: {remaining_time_min:.0f}m {remaining_time_sec:.0f}s\")\n\n    return train_loss_history, val_loss_history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"scrollTo=evaluation\"></a>\n### Model evaluation","metadata":{}},{"cell_type":"markdown","source":"The F1 score will be used as a basic evaluation metric. It is useful for evaluating models when there is class imbalance, as it provides a more balanced measure of the model's performance. The F1 score ranges from 0 (worst) to 1 (best).","metadata":{}},{"cell_type":"code","source":"def plot_confusion_matrix(predictions, y_test, title):\n    labels = ['Normal', 'Pnuemonia']\n    \n    cm = confusion_matrix(y_test,predictions)\n    cm = pd.DataFrame(cm , index = labels , columns = labels)\n    \n    plt.figure()\n    sns.heatmap(cm, cmap=\"YlGnBu\", linecolor = 'black' , linewidth = 1,\n                annot = True, fmt='', xticklabels = labels,\n                yticklabels = labels)\n    \n    plt.title(title, fontsize = 20)\n    plt.xlabel('Predicted', fontsize = 15)\n    plt.ylabel('Actual', fontsize = 15)\n    \n    plt.savefig('/kaggle/working/confusionMatrix.pdf',\n                format='pdf', bbox_inches='tight', dpi=300, transparent=True)\n    plt.show()\n    \n\ndef evaluate_model(h, model, data_loader, criterion, device):\n    true_labels = []\n    predicted_labels = []\n    total_loss = 0.0\n    correct = 0\n    total = 0\n    model.eval()\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs, labels = inputs.to(device), labels.to(device)          \n\n            outputs = model(inputs)\n\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            _, predicted = torch.max(outputs.data, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n            true_labels.extend(labels.cpu().numpy())\n            predicted_labels.extend(predicted.cpu().numpy())\n\n    epoch_loss = total_loss / len(data_loader)\n    epoch_accuracy = correct / total\n\n    return epoch_loss, epoch_accuracy, true_labels, predicted_labels\n\n\ndef plot_metrics(h, train_loss_history, val_loss_history, test_loss, test_accuracy, true_labels, predicted_labels):\n    print(f\"Accuracy on the test set: {test_accuracy:.2%}\")\n\n    # Calculate precision, recall, and F1 score using the accumulated true labels and predictions\n    precision = precision_score(true_labels, predicted_labels)\n    recall = recall_score(true_labels, predicted_labels)\n    f1 = f1_score(true_labels, predicted_labels)\n    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 score: {f1:.2f}\")\n\n    # Calculate the confusion matrix using the accumulated true labels and predictions\n    plot_confusion_matrix(predicted_labels, true_labels,\n                          'CNN with Data Augmentation and class weighting')\n\n    # Plot the learning curves\n    plt.figure()\n    plt.plot(train_loss_history, label='Train Loss')\n    plt.plot(val_loss_history, label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Loss history')\n    plt.legend()\n    plt.savefig('/kaggle/working/LossHistory.pdf',\n                format='pdf', bbox_inches='tight', dpi=300, transparent=True)\n    \n    plt.show()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"scrollTo=ss\"></a>\n### Running the model and Statistical Significance","metadata":{}},{"cell_type":"markdown","source":"Since the training process is random, the training and testing will be repeated several times to measure the statistical significance of the results.","metadata":{}},{"cell_type":"code","source":"def check_solution(h, device, verbose):\n    train_loader, val_loader, test_loader = prepare_data(h)\n    model = create_model(h, device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=h[\"lr\"])\n    criterion = nn.CrossEntropyLoss()\n    train_loss_history, val_loss_history = train_model(h, model, train_loader,\n                                                       val_loader, optimizer, criterion, device)\n    test_loss, test_accuracy, true_labels, predicted_labels = evaluate_model(h, model, test_loader,\n                                                                             criterion, device)\n    if verbose:\n        plot_metrics(h, train_loss_history, val_loss_history, test_loss, test_accuracy,\n                     true_labels, predicted_labels)\n\n    f1 = f1_score(true_labels, predicted_labels)\n\n    return f1, test_accuracy\n\n\n# Print hyperparameters for records\nprint(\"Hyperparameters:\")\npprint.pprint(h)\n\nf1_array = np.array([])\naccuracy_array = np.array([])\nstart_time = time.time()\n\nrepeats = 4\nfor i in range(repeats):\n    print(f\"Running solution {i+1}/{repeats}\")\n    f1, accuracy = check_solution(h, device, verbose=(i==0))\n    print(f\"F1 = {f1:.2f}, accuracy = {accuracy:.2f} \")\n    f1_array = np.append(f1_array, f1)\n    accuracy_array = np.append(accuracy_array, accuracy) \n\n# Calculate elapsed time and remaining time\nrepeat_time = (time.time() - start_time) / repeats\nrepeat_time_min, repeat_time_sec = divmod(repeat_time, 60)\n\n# Printing final results\nprint(\"Results\")\nprint(f\"F1 List: {f1_array}\")\nprint(f\"Accuracy List: {accuracy_array}\")\nprint(f\"F1: {np.mean(f1_array):.1%} (+-{np.std(f1_array):.1%})\")\nprint(f\"Accuracy: {np.mean(accuracy_array):.1%} (+-{np.std(accuracy_array):.1%})\")\nprint(f\"Time of one solution: {repeat_time_min:.0f}m {repeat_time_sec:.0f}s\")\n\nprint(f\" | {np.mean(f1_array):.1%} (+-{np.std(f1_array):.1%}) | {np.mean(accuracy_array):.1%} (+-{np.std(accuracy_array):.1%}) | {repeat_time_min:.0f}m {repeat_time_sec:.0f}s\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"scrollTo=results\"></a>\n## Results and comparison with Classical ML","metadata":{}},{"cell_type":"markdown","source":"<a id=\"scrollTo=improve\"></a>\n### Deep learning potential improvements\n\nPotential CNN improvements could include the introduction of a Learning rate scheduler and early stopping with model checkpointing.\n\nAlso leveraging a pretrained models such as [ResNet34](http://pytorch.org/vision/main/models/generated/torchvision.models.resnet34.html) could be of help. transfer learning by using a pre-trained ResNet34 network. Transfer learning is a technique where we use a pre-trained model, which has already learned features from a large dataset, to solve a similar problem. This could potentially help the NN achieve better performance and reduce training time, as the model has already learned useful features from the large dataset.","metadata":{}}]}